{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N observations with D parameters\n",
    "N = 1024\n",
    "D = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_true = np.random.uniform(-2, 2, D).reshape(D, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(n, beta, link='linear', sigma=3.0):\n",
    "    \"\"\"Generate data for GLM.\n",
    "    \n",
    "    # Arguments\n",
    "        N: number of observations\n",
    "        beta: regression coefficient vector\n",
    "        link: linear or logistic\n",
    "        sigma: standard deviation of Gaussian noise (only for linear regression)\n",
    "        \n",
    "    # Returns\n",
    "        A list of design matrix and response vector\n",
    "    \"\"\"\n",
    "    d = beta.shape[0]\n",
    "    X = np.random.normal(0, 1, n * d).reshape(n, d)\n",
    "    eta = np.dot(X, beta)\n",
    "    if link == 'linear':\n",
    "        mu = eta\n",
    "        Y = eta + np.random.normal(0, sigma, n).reshape(n, 1)\n",
    "    elif link == 'logistic':\n",
    "        mu = 1.0 / np.exp(-eta)\n",
    "        Y = (mu > 0.5).astype(float)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataX, dataY = generateData(N, beta_true, link='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('dataX.csv', dataX)\n",
    "np.savetxt('dataY.csv', dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best linear unbiased estimate\n",
    "def lm(X, Y):\n",
    "    estimate = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X), X)), np.transpose(X)), Y)\n",
    "    return(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_hat = lm(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# placeholding tensors and variable\n",
    "X = tf.placeholder('float', [None, D]) \n",
    "Y = tf.placeholder('float', [None, 1])\n",
    "beta = tf.Variable(tf.random_normal([D, 1], stddev=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear regression with mean squared error\n",
    "Y_hat = tf.matmul(X, beta)\n",
    "loss = tf.reduce_sum(tf.square(Y - Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic regression with log loss\n",
    "eta = tf.matmul(X, beta)\n",
    "p = 1.0 / tf.exp(-eta)\n",
    "loss = -1.0 * (tf.reduce_sum(Y * tf.log(p) + (1.0 - Y) * tf.log(1 - p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gradient of loss function\n",
    "grad = tf.gradients(loss, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hessian (or use tf.hessians in Tensorflow 1.0)\n",
    "def compute_hessian():\n",
    "    for i in range(D):\n",
    "        # element in the gradient vector\n",
    "        dfdx_i = tf.slice(grad[0], begin=[i, 0], size=[1, 1])\n",
    "        # differentiate again\n",
    "        ddfdx2_i = tf.gradients(dfdx_i, beta)[0]\n",
    "        # combine second derivative vectors\n",
    "        if i == 0:\n",
    "            hess = ddfdx2_i\n",
    "        else:\n",
    "            hess = tf.concat(1, [hess, ddfdx2_i])\n",
    "    return(hess)\n",
    "\n",
    "hessian = compute_hessian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fisher information\n",
    "fisher = tf.matrix_inverse(hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update beta by delta\n",
    "delta = tf.placeholder('float', [D, 1])\n",
    "descent = beta.assign_add(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hadamard(k):\n",
    "    \"\"\"Create standard Hadamard matrix.\n",
    "    \n",
    "    # Arguments\n",
    "        k: power of 2\n",
    "    \n",
    "    # Returns\n",
    "        A Hadamard matrix of size 2 ^ k\n",
    "    \"\"\"\n",
    "    H2 = np.ones((2, 2))\n",
    "    H2[1, 1] = -1.0\n",
    "    H2 = H2 / np.sqrt(2)\n",
    "    H = 1.0\n",
    "    for i in range(0, k):\n",
    "        H = np.kron(H2, H)\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sketch(X, Y, R, method='gaussian', sampling=False, bootstrap=False):\n",
    "    \"\"\"Randomly data projection.\n",
    "    \n",
    "    # Arguments\n",
    "        X: design matrix\n",
    "        Y: response vector\n",
    "        R: projection dimension\n",
    "        \n",
    "    # Usage\n",
    "        Subsampling: method='none', sampling=True, bootstrap=True\n",
    "        i.i.d Gaussian: method='gaussian', sampling=False, bootstrap=False\n",
    "        Hadamard: method='hadamard', sampling=True, bootstrap=False\n",
    "    \n",
    "    # Returns\n",
    "        A list of design matrix and response vector in projection space\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    SX = X\n",
    "    SY = Y\n",
    "    if method == 'gaussian':\n",
    "        S = np.random.normal(0, 1, R * N).reshape(R, N)\n",
    "        SX = np.dot(S, X)\n",
    "        SY = np.dot(S, Y)\n",
    "    elif method == 'hadamard':\n",
    "        H = hadamard(int(np.log2(N)))\n",
    "        temp = np.ones(N)\n",
    "        temp[np.random.randint(low=0, high=N, size=int(N / 2))] = -1.0\n",
    "        D = np.diag(temp)\n",
    "        S = np.dot(H, D)\n",
    "        SX = np.dot(S, X)\n",
    "        SY = np.dot(S, Y)\n",
    "    if sampling:\n",
    "        select = np.random.choice(np.array(range(0, N)), size=R, replace=bootstrap)\n",
    "        SX = SX[select, :]\n",
    "        SY = SY[select, :]\n",
    "    return(SX, SY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample path\n",
    "path = np.zeros((50, 50))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for i in range(0, 50):\n",
    "        # sketching\n",
    "        sketchX, sketchY = sketch(dataX, dataY, 256, method='gaussian', sampling=False, bootstrap=False)\n",
    "        # compute gradient\n",
    "        g = sess.run(grad, feed_dict={X: sketchX, Y: sketchY})[0]\n",
    "        # compute hessian\n",
    "        I = sess.run(fisher, feed_dict={X: sketchX, Y: sketchY})\n",
    "        # update beta\n",
    "        sess.run(descent, feed_dict={delta : -np.dot(I, g)})\n",
    "        path[i, :] = np.transpose(beta.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('gaussian.csv', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# arrays to store results\n",
    "B_hat = np.zeros((100, D))\n",
    "B_sketch = np.zeros((100, D))\n",
    "\n",
    "# simulate 100 times\n",
    "for i in range(0, 100):\n",
    "    dataX, dataY = generateData(N, beta_true, link='linear')\n",
    "    B_hat[i, :] = np.transpose(lm(dataX, dataY))\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for j in range(0, 10):\n",
    "            sketchX, sketchY = sketch(dataX, dataY, 512, method='hadamard', sampling=True, bootstrap=False)\n",
    "            g = sess.run(grad, feed_dict={X: sketchX, Y: sketchY})[0]\n",
    "            I = sess.run(fisher, feed_dict={X: sketchX, Y: sketchY})\n",
    "            sess.run(descent, feed_dict={delta : -np.dot(I, g)})\n",
    "        B_sketch[i, :] = np.transpose(beta.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = np.mean(np.square(B_sketch - np.transpose(beta_true))) / np.mean(np.square(B_hat - np.transpose(beta_true)))\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
